

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Configuration &mdash; hls4ml 1.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/sphinx_contributors.css?v=f079e67e" />

  
    <link rel="shortcut icon" href="../_static/hls4ml_logo.svg"/>
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=fc837d61"></script>
      <script src="../_static/doctools.js?v=9a2dae69"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Command Line Interface (deprecated)" href="command.html" />
    <link rel="prev" title="Concepts" href="concepts.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #2980B9" >

          
          
          <a href="../index.html">
            
              <img src="../_static/hls4ml_logo_navbar.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intro/introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/status.html">Status and Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/setup.html">Setup and Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/faq.html">Frequently asked questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/release_notes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/reference.html">Citation, Acknowledgments, and Contributors</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="concepts.html">Concepts</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Configuration</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#python-api">1. Python API</a></li>
<li class="toctree-l2"><a class="reference internal" href="#yaml-configuration-file">2. YAML Configuration file</a></li>
<li class="toctree-l2"><a class="reference internal" href="#detailed-configuration-in-converted-hls-code">Detailed Configuration in Converted HLS Code</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="command.html">Command Line Interface (deprecated)</a></li>
<li class="toctree-l1"><a class="reference internal" href="serialization.html">Saving/Loading hls4ml models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Frontends</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../frontend/keras.html">Keras and its quantized variants</a></li>
<li class="toctree-l1"><a class="reference internal" href="../frontend/pytorch.html">PyTorch and Brevitas</a></li>
<li class="toctree-l1"><a class="reference internal" href="../frontend/qonnx.html">ONNX and QONNX</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Backends</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../backend/vitis.html">Vivado/Vitis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/accelerator.html">VivadoAccelerator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/oneapi.html">oneAPI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/catapult.html">Catapult</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/quartus.html">Quartus</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/sr.html">SymbolicExpression</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Features</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced/profiling.html">Profiling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/auto.html">Automatic precision inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/hgq.html">High Granularity Quantization (HGQ)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/fifo_depth.html">FIFO Buffer Depth Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/extension.html">Extension API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/model_optimization.html">Hardware-aware Optimization API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/bramfactor.html">Loading weights from external BRAM</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Internals</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../ir/ir.html">Internal representation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ir/modelgraph.html">ModelGraph Class</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ir/multimodelgraph.html">MultiModelGraph Class</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ir/flows.html">Optimizer Passes and Flows</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ir/attributes.html">Layer attributes</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Autogenerated API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../autodoc/hls4ml.backends.html">hls4ml.backends package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../autodoc/hls4ml.converters.html">hls4ml.converters package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../autodoc/hls4ml.model.html">hls4ml.model package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../autodoc/hls4ml.optimization.html">hls4ml.optimization package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../autodoc/hls4ml.report.html">hls4ml.report package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../autodoc/hls4ml.utils.html">hls4ml.utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../autodoc/hls4ml.writer.html">hls4ml.writer package</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #2980B9" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">hls4ml</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Configuration</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/fastmachinelearning/hls4ml/blob/main/docs/api/configuration.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="configuration">
<h1><a class="toc-backref" href="#id2" role="doc-backlink">Configuration</a><a class="headerlink" href="#configuration" title="Link to this heading"></a></h1>
<p>We currently support two ways of setting hls4ml’s model configuration. This page documents both methods’ usage.</p>
<nav class="contents" id="id1">
<p class="topic-title"></p>
<ul class="simple">
<li><p><a class="reference internal" href="#configuration" id="id2">Configuration</a></p>
<ul>
<li><p><a class="reference internal" href="#python-api" id="id3">1. Python API</a></p></li>
<li><p><a class="reference internal" href="#yaml-configuration-file" id="id4">2. YAML Configuration file</a></p>
<ul>
<li><p><a class="reference internal" href="#top-level-configuration" id="id5">2.1 Top Level Configuration</a></p></li>
<li><p><a class="reference internal" href="#per-layer-configuration" id="id6">2.2 Per-Layer Configuration</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#detailed-configuration-in-converted-hls-code" id="id7">Detailed Configuration in Converted HLS Code</a></p></li>
</ul>
</li>
</ul>
</nav>
<p>The Python API approach is recommended for most users as there are more utilities to help create the configuration dictionaries.</p>
<p><strong>NOTE:</strong></p>
<ul class="simple">
<li><p>One important part of <code class="docutils literal notranslate"><span class="pre">hls4ml</span></code> to remember is that the user is responsible for the format of the inputs.  There is no automatic formatting or normalization so this must be done in the training.</p></li>
</ul>
<hr class="docutils" />
<section id="python-api">
<h2><a class="toc-backref" href="#id3" role="doc-backlink">1. Python API</a><a class="headerlink" href="#python-api" title="Link to this heading"></a></h2>
<p>Using hls4ml, you can quickly generate a simple configuration dictionary from a keras model:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">hls4ml</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">hls4ml</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">config_from_keras_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">granularity</span><span class="o">=</span><span class="s1">&#39;model&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>This python dictionary can be edited as needed. More advanced configuration can be generated by, for example for ONNX models:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">hls4ml</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">hls4ml</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">config_from_onnx_model</span><span class="p">(</span>
     <span class="n">model</span><span class="p">,</span>
     <span class="n">granularity</span><span class="o">=</span><span class="s1">&#39;name&#39;</span><span class="p">,</span>
     <span class="n">default_precision</span><span class="o">=</span><span class="s1">&#39;fixed&lt;16,6&gt;&#39;</span><span class="p">,</span>
     <span class="n">backend</span><span class="o">=</span><span class="s1">&#39;Vitis&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>for Keras models:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">hls4ml</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">hls4ml</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">config_from_keras_model</span><span class="p">(</span>
     <span class="n">model</span><span class="p">,</span>
     <span class="n">granularity</span><span class="o">=</span><span class="s1">&#39;name&#39;</span><span class="p">,</span>
     <span class="n">default_precision</span><span class="o">=</span><span class="s1">&#39;fixed&lt;16,6&gt;&#39;</span><span class="p">,</span>
     <span class="n">backend</span><span class="o">=</span><span class="s1">&#39;oneAPI&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>or for PyTorch models:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">hls4ml</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">hls4ml</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">config_from_pytorch_model</span><span class="p">(</span>
     <span class="n">model</span><span class="p">,</span>
     <span class="n">granularity</span><span class="o">=</span><span class="s1">&#39;name&#39;</span><span class="p">,</span>
     <span class="n">default_precision</span><span class="o">=</span><span class="s1">&#39;fixed&lt;16,6&gt;&#39;</span><span class="p">,</span>
     <span class="n">backend</span><span class="o">=</span><span class="s1">&#39;Catapult&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">name</span></code> granularity includes per-layer configuration based on the model. A <code class="docutils literal notranslate"><span class="pre">'name'</span></code> granularity is generally recommended because it allows for more turning, and also because it allows
for automatic setting of precisions.  The layer-level precisions with the <code class="docutils literal notranslate"><span class="pre">'name'</span></code> granularity default to <code class="docutils literal notranslate"><span class="pre">'auto'</span></code>, which means that hls4ml will try to set it automatically
(see <a class="reference internal" href="../advanced/auto.html#automatic-precision-inference"><span class="std std-ref">Automatic precision inference</span></a>). Note that layer-level settings take precedence over model-level settings. A <code class="docutils literal notranslate"><span class="pre">'name'</span></code> granularity is required for QKeras
and QONNX model parsing. Passing the backend to these functions is recommended because some configuration options depend on the backend. See <a class="reference internal" href="../autodoc/hls4ml.utils.html#hls4ml.utils.config.config_from_keras_model" title="hls4ml.utils.config.config_from_keras_model"><code class="xref py py-class docutils literal notranslate"><span class="pre">config_from_keras_model</span></code></a>
and similar for more information on the various options. Note specifically the documentation of <a class="reference internal" href="../autodoc/hls4ml.utils.html#hls4ml.utils.config.config_from_pytorch_model" title="hls4ml.utils.config.config_from_pytorch_model"><code class="xref py py-class docutils literal notranslate"><span class="pre">config_from_pytorch_model</span></code></a> on how to handle differences in input data
formats between pytorch and keras (hls4ml follows keras conventions internally).</p>
<p>One can override specific values before using the configuration:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;LayerName&#39;</span><span class="p">][</span><span class="s1">&#39;fc1&#39;</span><span class="p">][</span><span class="s1">&#39;ReuseFactor&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>
</pre></div>
</div>
<p>Or to set the precision of a specific layer’s weight:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;LayerName&#39;</span><span class="p">][</span><span class="s1">&#39;fc1&#39;</span><span class="p">][</span><span class="s1">&#39;Precision&#39;</span><span class="p">][</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;fixed&lt;8,4&gt;&#39;</span>
</pre></div>
</div>
<p>To better understand how the configuration hierachy works, refer to the next section for more details.</p>
<p>Finally, one then uses the configuration to create an hls model:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">hls_model</span> <span class="o">=</span> <span class="n">hls4ml</span><span class="o">.</span><span class="n">converters</span><span class="o">.</span><span class="n">convert_from_keras_model</span><span class="p">(</span>
      <span class="n">model</span><span class="p">,</span>
      <span class="n">hls_config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span>
      <span class="n">output_dir</span><span class="o">=</span><span class="s2">&quot;my_project_dir&quot;</span><span class="p">,</span>
      <span class="n">io_type</span><span class="o">=</span><span class="s1">&#39;io_stream&#39;</span><span class="p">,</span>
      <span class="n">backend</span><span class="o">=</span><span class="s1">&#39;Vitis&#39;</span>
  <span class="p">)</span>
</pre></div>
</div>
<p>See <a class="reference internal" href="../autodoc/hls4ml.converters.html#hls4ml.converters.convert_from_keras_model" title="hls4ml.converters.convert_from_keras_model"><code class="xref py py-class docutils literal notranslate"><span class="pre">convert_from_keras_model</span></code></a> for more information on the various options. Similar functions exist for ONNX and PyTorch.</p>
</section>
<hr class="docutils" />
<section id="yaml-configuration-file">
<h2><a class="toc-backref" href="#id4" role="doc-backlink">2. YAML Configuration file</a><a class="headerlink" href="#yaml-configuration-file" title="Link to this heading"></a></h2>
<section id="top-level-configuration">
<h3><a class="toc-backref" href="#id5" role="doc-backlink">2.1 Top Level Configuration</a><a class="headerlink" href="#top-level-configuration" title="Link to this heading"></a></h3>
<p>One can also use YAML configuration files in hls4ml (<code class="docutils literal notranslate"><span class="pre">*.yml</span></code>). An example configuration file is <a class="reference external" href="https://github.com/hls-fpga-machine-learning/example-models/blob/master/keras-config.yml">here</a>.</p>
<p>It looks like this:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="c1"># Project section</span>
<span class="nt">OutputDir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">my-hls-test</span>
<span class="nt">ProjectName</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">myproject</span>

<span class="c1"># Model section (Keras model)</span>
<span class="nt">KerasJson</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">keras/KERAS_3layer.json</span>
<span class="nt">KerasH5</span><span class="p">:</span><span class="w">   </span><span class="l l-Scalar l-Scalar-Plain">keras/KERAS_3layer_weights.h5</span><span class="w"> </span><span class="c1">#You can also use h5 file from Keras&#39;s model.save() without supplying json file.</span>
<span class="nt">InputData</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">keras/KERAS_3layer_input_features.dat</span>
<span class="nt">OutputPredictions</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">keras/KERAS_3layer_predictions.dat</span>

<span class="c1"># Backend section (Vivado backend)</span>
<span class="nt">Part</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">xcvu13p-flga2577-2-e</span>
<span class="nt">ClockPeriod</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">5</span>
<span class="nt">IOType</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">io_parallel</span><span class="w"> </span><span class="c1"># options: io_parallel/io_stream</span>

<span class="nt">HLSConfig</span><span class="p">:</span>
<span class="w">  </span><span class="nt">Model</span><span class="p">:</span>
<span class="w">    </span><span class="nt">Precision</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">fixed&lt;16,6&gt;</span>
<span class="w">    </span><span class="nt">ReuseFactor</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">    </span><span class="nt">Strategy</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Latency</span>
<span class="w">  </span><span class="nt">LayerType</span><span class="p">:</span>
<span class="w">    </span><span class="nt">Dense</span><span class="p">:</span>
<span class="w">      </span><span class="nt">ReuseFactor</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="w">      </span><span class="nt">Strategy</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Resource</span>
<span class="w">      </span><span class="nt">Compression</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">True</span>
</pre></div>
</div>
<p>There are a number of configuration options that you have.  Let’s go through them.  You have basic setup parameters:</p>
<ul class="simple">
<li><p><strong>OutputDir</strong>: the output directory where you want your HLS project to appear</p></li>
<li><p><strong>ProjectName</strong>: the name of the HLS project IP that is produced</p></li>
<li><p><strong>KerasJson/KerasH5</strong>: for Keras, the model architecture and weights are stored in a <code class="docutils literal notranslate"><span class="pre">json</span></code> and <code class="docutils literal notranslate"><span class="pre">h5</span></code> file.  The path to those files are required here.
We also support keras model’s file obtained just from <code class="docutils literal notranslate"><span class="pre">model.save()</span></code>. In this case you can just supply the <code class="docutils literal notranslate"><span class="pre">h5</span></code> file in <code class="docutils literal notranslate"><span class="pre">KerasH5:</span></code> field.</p></li>
<li><p><strong>InputData/OutputPredictions</strong>: path to your input/predictions of the model. If none is supplied, then hls4ml will create artificial data for simulation. The data used above in the example can be found <a class="reference external" href="https://cernbox.cern.ch/index.php/s/2LTJVVwCYFfkg59">here</a>. We also support <code class="docutils literal notranslate"><span class="pre">npy</span></code> data files. We welcome suggestions on more input data types to support.</p></li>
</ul>
<p>The backend-specific section of the configuration depends on the backend. You can get a starting point for the necessary settings using, for example <cite>hls4ml.templates.get_backend(‘Vivado’).create_initial_config()</cite>.
For Vivado backend the options are:</p>
<ul class="simple">
<li><p><strong>Part</strong>: the particular FPGA part number that you are considering, here it’s a Xilinx Virtex UltraScale+ VU13P FPGA</p></li>
<li><p><strong>ClockPeriod</strong>: the clock period, in ns, at which your algorithm runs
Then you have some optimization parameters for how your algorithm runs:</p></li>
<li><p><strong>IOType</strong>: your options are <code class="docutils literal notranslate"><span class="pre">io_parallel</span></code> or <code class="docutils literal notranslate"><span class="pre">io_stream</span></code> which defines the type of data structure used for inputs, intermediate activations between layers, and outputs. For <code class="docutils literal notranslate"><span class="pre">io_parallel</span></code>, arrays are used that, in principle, can be fully unrolled and are typically implemented in RAMs. For <code class="docutils literal notranslate"><span class="pre">io_stream</span></code>, HLS streams are used, which are a more efficient/scalable mechanism to represent data that are produced and consumed in a sequential manner. Typically, HLS streams are implemented with FIFOs instead of RAMs. For more information see <a class="reference external" href="https://docs.xilinx.com/r/en-US/ug1399-vitis-hls/pragma-HLS-stream">here</a>.</p></li>
<li><p><strong>HLSConfig</strong>: the detailed configuration of precision and parallelism, including:</p>
<ul>
<li><p><strong>ReuseFactor</strong>: in the case that you are pipelining, this defines the pipeline interval or initiation interval</p></li>
<li><p><strong>ParallelizationFactor</strong>: The number of output “pixels” to compute in parallel in convolutional layers. Increasing this parameter results in significant increase in resources required on the FPGA.</p></li>
<li><p><strong>Strategy</strong>: Optimization strategy on FPGA, either “Latency”, “Resource” or “Unrolled”. If none is supplied then hl4ml uses “Latency” as default. Note that a reuse factor larger than 1 should be specified when using “resource” or “unrolled” strategy. An example of using larger reuse factor can be found <a class="reference external" href="https://github.com/fastmachinelearning/models/tree/master/keras/KERAS_dense">here.</a></p></li>
<li><p><strong>PipelineStyle</strong>: Set the top level pipeline style. Valid options are “auto”, “pipeline” and “dataflow”. If unspecified, it defaults to “auto”.</p></li>
<li><p><strong>PipelineInterval</strong>: Optionally override the desired initiation interval of the design. Only valid in combination with “pipeline” style. If unspecified, it is left to the compiler to decide, ideally matching the largest reuse factor of the network.</p></li>
<li><p><strong>Precision</strong>: this defines the precision of your inputs, outputs, weights and biases. It is denoted by <code class="docutils literal notranslate"><span class="pre">fixed&lt;X,Y&gt;</span></code>, where <code class="docutils literal notranslate"><span class="pre">Y</span></code> is the number of bits representing the signed number above the binary point (i.e. the integer part), and <code class="docutils literal notranslate"><span class="pre">X</span></code> is the total number of bits. Additionally, integers in the type (<code class="docutils literal notranslate"><span class="pre">int&lt;N&gt;</span></code>, where <code class="docutils literal notranslate"><span class="pre">N</span></code> is a bit-size from 1 to 1024) can also be used. The format follows <code class="docutils literal notranslate"><span class="pre">ap_fixed</span></code> and <code class="docutils literal notranslate"><span class="pre">ap_int</span></code> conventions. You have a chance to further configure this more finely with per-layer configuration described below. In the per-layer configuration (but not globally) one can also use <code class="docutils literal notranslate"><span class="pre">'auto'</span></code> precision.</p></li>
</ul>
</li>
</ul>
</section>
<section id="per-layer-configuration">
<h3><a class="toc-backref" href="#id6" role="doc-backlink">2.2 Per-Layer Configuration</a><a class="headerlink" href="#per-layer-configuration" title="Link to this heading"></a></h3>
<p>In the <code class="docutils literal notranslate"><span class="pre">hls4ml</span></code> configuration file, it is possible to specify the model <em>Precision</em> and <em>ReuseFactor</em> with finer granularity.</p>
<p>Under the <code class="docutils literal notranslate"><span class="pre">HLSConfig</span></code> heading, these can be set for the <code class="docutils literal notranslate"><span class="pre">Model</span></code>, per <code class="docutils literal notranslate"><span class="pre">LayerType</span></code>, per <code class="docutils literal notranslate"><span class="pre">LayerName</span></code>, and for named variables within the layer (for precision only). The most basic configuration may look like this:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">HLSConfig</span><span class="p">:</span>
<span class="w">  </span><span class="nt">Model</span><span class="p">:</span>
<span class="w">    </span><span class="nt">Precision</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">fixed&lt;16,6&gt;</span>
<span class="w">    </span><span class="nt">ReuseFactor</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
</pre></div>
</div>
<p>This configuration use <code class="docutils literal notranslate"><span class="pre">fixed&lt;16,6&gt;</span></code> for every variable and a ReuseFactor of 1 throughout.</p>
<p>Specify all <code class="docutils literal notranslate"><span class="pre">Dense</span></code> layers to use a different precision like this:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">HLSConfig</span><span class="p">:</span>
<span class="w">  </span><span class="nt">Model</span><span class="p">:</span>
<span class="w">    </span><span class="nt">Precision</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">fixed&lt;16,6&gt;</span>
<span class="w">    </span><span class="nt">ReuseFactor</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">  </span><span class="nt">LayerType</span><span class="p">:</span>
<span class="w">    </span><span class="nt">Dense</span><span class="p">:</span>
<span class="w">      </span><span class="nt">Precision</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">fixed&lt;14,5&gt;</span>
</pre></div>
</div>
<p>In this case, all variables in any <code class="docutils literal notranslate"><span class="pre">Dense</span></code> layers will be represented with <code class="docutils literal notranslate"><span class="pre">fixed&lt;14,5&gt;</span></code> while any other layer types will use <code class="docutils literal notranslate"><span class="pre">fixed&lt;16,6&gt;</span></code>.</p>
<p>A specific layer can be targeted like this:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">HLSConfig</span><span class="p">:</span>
<span class="w">   </span><span class="nt">Model</span><span class="p">:</span>
<span class="w">     </span><span class="nt">Precision</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">fixed&lt;16,6&gt;</span>
<span class="w">     </span><span class="nt">ReuseFactor</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">16</span>
<span class="w">   </span><span class="nt">LayerName</span><span class="p">:</span>
<span class="w">     </span><span class="nt">dense1</span><span class="p">:</span>
<span class="w">       </span><span class="nt">Precision</span><span class="p">:</span>
<span class="w">         </span><span class="nt">weight</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">fixed&lt;14,2&gt;</span>
<span class="w">         </span><span class="nt">bias</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">fixed&lt;14,4&gt;</span>
<span class="w">         </span><span class="nt">result</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">fixed&lt;16,6&gt;</span>
<span class="w">       </span><span class="nt">ReuseFactor</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">12</span>
<span class="w">       </span><span class="nt">Strategy</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Resource</span>
</pre></div>
</div>
<p>In this case, the default model configuration will use <code class="docutils literal notranslate"><span class="pre">fixed&lt;16,6&gt;</span></code> and a <code class="docutils literal notranslate"><span class="pre">ReuseFactor</span></code> of 16. The layer named <code class="docutils literal notranslate"><span class="pre">dense1</span></code> (defined in the user provided model architecture file) will instead use different precision for the <code class="docutils literal notranslate"><span class="pre">weight</span></code>, <code class="docutils literal notranslate"><span class="pre">bias</span></code>, and <code class="docutils literal notranslate"><span class="pre">result</span></code> (output) variables, a <code class="docutils literal notranslate"><span class="pre">ReuseFactor</span></code> of 12, and the <code class="docutils literal notranslate"><span class="pre">Resource</span></code> strategy (while the model default is <code class="docutils literal notranslate"><span class="pre">Latency</span></code> strategy.</p>
<p>More than one layer can have a configuration specified, e.g.:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">HLSConfig</span><span class="p">:</span>
<span class="w">  </span><span class="nt">Model</span><span class="p">:</span>
<span class="w">   </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">  </span><span class="nt">LayerName</span><span class="p">:</span>
<span class="w">    </span><span class="nt">dense1</span><span class="p">:</span>
<span class="w">       </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">    </span><span class="nt">batchnormalization1</span><span class="p">:</span>
<span class="w">       </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">    </span><span class="nt">dense2</span><span class="p">:</span>
<span class="w">       </span><span class="l l-Scalar l-Scalar-Plain">...</span>
</pre></div>
</div>
<p>For more information on the optimization parameters and what they mean, you can visit the <a class="reference internal" href="concepts.html"><span class="doc">Concepts</span></a> section.</p>
</section>
</section>
<hr class="docutils" />
<section id="detailed-configuration-in-converted-hls-code">
<h2><a class="toc-backref" href="#id7" role="doc-backlink">Detailed Configuration in Converted HLS Code</a><a class="headerlink" href="#detailed-configuration-in-converted-hls-code" title="Link to this heading"></a></h2>
<p><strong>NOTE</strong>: this section is developer-oriented.</p>
<p>After you create your project, you have the opportunity to do more configuration if you so choose.</p>
<p>In your project, the file <code class="docutils literal notranslate"><span class="pre">&lt;OutputDir&gt;/firmware/&lt;ProjectName&gt;.cpp</span></code> is your top level file.  It has the network architecture constructed for you.  An example is <a class="reference external" href="https://github.com/hls-fpga-machine-learning/models/blob/master/HLS_projects/KERAS-1layer-hls/firmware/myproject.cpp">here</a> and the important snippet is:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">layer2_t</span><span class="w"> </span><span class="n">layer2_out</span><span class="p">[</span><span class="n">N_LAYER_2</span><span class="p">];</span>
<span class="cp">#pragma HLS ARRAY_PARTITION variable=layer2_out complete dim=0</span>
<span class="n">nnet</span><span class="o">::</span><span class="n">dense_latency</span><span class="o">&lt;</span><span class="n">input_t</span><span class="p">,</span><span class="w"> </span><span class="n">layer2_t</span><span class="p">,</span><span class="w"> </span><span class="n">config2</span><span class="o">&gt;</span><span class="p">(</span><span class="n">input_1</span><span class="p">,</span><span class="w"> </span><span class="n">layer2_out</span><span class="p">,</span><span class="w"> </span><span class="n">w2</span><span class="p">,</span><span class="w"> </span><span class="n">b2</span><span class="p">);</span>

<span class="n">layer3_t</span><span class="w"> </span><span class="n">layer3_out</span><span class="p">[</span><span class="n">N_LAYER_2</span><span class="p">];</span>
<span class="cp">#pragma HLS ARRAY_PARTITION variable=layer3_out complete dim=0</span>
<span class="n">nnet</span><span class="o">::</span><span class="n">relu</span><span class="o">&lt;</span><span class="n">layer2_t</span><span class="p">,</span><span class="w"> </span><span class="n">layer3_t</span><span class="p">,</span><span class="w"> </span><span class="n">relu_config3</span><span class="o">&gt;</span><span class="p">(</span><span class="n">layer2_out</span><span class="p">,</span><span class="w"> </span><span class="n">layer3_out</span><span class="p">);</span>

<span class="n">layer4_t</span><span class="w"> </span><span class="n">layer4_out</span><span class="p">[</span><span class="n">N_LAYER_4</span><span class="p">];</span>
<span class="cp">#pragma HLS ARRAY_PARTITION variable=layer4_out complete dim=0</span>
<span class="n">nnet</span><span class="o">::</span><span class="n">dense_latency</span><span class="o">&lt;</span><span class="n">layer3_t</span><span class="p">,</span><span class="w"> </span><span class="n">layer4_t</span><span class="p">,</span><span class="w"> </span><span class="n">config4</span><span class="o">&gt;</span><span class="p">(</span><span class="n">layer3_out</span><span class="p">,</span><span class="w"> </span><span class="n">layer4_out</span><span class="p">,</span><span class="w"> </span><span class="n">w4</span><span class="p">,</span><span class="w"> </span><span class="n">b4</span><span class="p">);</span>

<span class="n">nnet</span><span class="o">::</span><span class="n">sigmoid</span><span class="o">&lt;</span><span class="n">layer4_t</span><span class="p">,</span><span class="w"> </span><span class="n">result_t</span><span class="p">,</span><span class="w"> </span><span class="n">sigmoid_config5</span><span class="o">&gt;</span><span class="p">(</span><span class="n">layer4_out</span><span class="p">,</span><span class="w"> </span><span class="n">layer5_out</span><span class="p">);</span>
</pre></div>
</div>
<p>You can see, for the simple 1-layer DNN, the computation (<code class="docutils literal notranslate"><span class="pre">nnet::dense_latency</span></code>) and activation (<code class="docutils literal notranslate"><span class="pre">nnet::relu</span></code>/<code class="docutils literal notranslate"><span class="pre">nnet::sigmoid</span></code>) calculation for each layer.  For each layer, it has its own additional configuration parameters, e.g. <code class="docutils literal notranslate"><span class="pre">config2</span></code>.</p>
<p>In your project, the file <code class="docutils literal notranslate"><span class="pre">&lt;OutputDir&gt;/firmware/parameters.h</span></code> stores all the configuration options for each neural network library.
An example is <a class="reference external" href="https://github.com/hls-fpga-machine-learning/models/blob/master/HLS_projects/KERAS-1layer-hls/firmware/parameters.h">here</a>. So for example, the detailed configuration options for an example DNN layer is:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">//hls-fpga-machine-learning insert layer-config</span>
<span class="k">struct</span><span class="w"> </span><span class="nc">config2</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">nnet</span><span class="o">::</span><span class="n">dense_config</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">static</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n_in</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">N_INPUT_1_1</span><span class="p">;</span>
<span class="w">    </span><span class="k">static</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n_out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">N_LAYER_2</span><span class="p">;</span>
<span class="w">    </span><span class="k">static</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">io_type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">nnet</span><span class="o">::</span><span class="n">io_parallel</span><span class="p">;</span>
<span class="w">    </span><span class="k">static</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">reuse_factor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">    </span><span class="k">static</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n_zeros</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">    </span><span class="k">static</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n_nonzeros</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">320</span><span class="p">;</span>
<span class="w">    </span><span class="k">static</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">store_weights_in_bram</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">false</span><span class="p">;</span>
<span class="w">    </span><span class="k">typedef</span><span class="w"> </span><span class="n">ap_fixed</span><span class="o">&lt;</span><span class="mi">16</span><span class="p">,</span><span class="mi">6</span><span class="o">&gt;</span><span class="w"> </span><span class="n">accum_t</span><span class="p">;</span>
<span class="w">    </span><span class="k">typedef</span><span class="w"> </span><span class="n">model_default_t</span><span class="w"> </span><span class="n">bias_t</span><span class="p">;</span>
<span class="w">    </span><span class="k">typedef</span><span class="w"> </span><span class="n">model_default_t</span><span class="w"> </span><span class="n">weight_t</span><span class="p">;</span>
<span class="w">    </span><span class="k">typedef</span><span class="w"> </span><span class="n">ap_uint</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="w"> </span><span class="n">index_t</span><span class="p">;</span>
<span class="p">};</span>
</pre></div>
</div>
<p>It is at this stage that a user can even further configure their network HLS implementation in finer detail.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="concepts.html" class="btn btn-neutral float-left" title="Concepts" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="command.html" class="btn btn-neutral float-right" title="Command Line Interface (deprecated)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Fast Machine Learning Lab.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>